import streamlit as st
import plotly.graph_objects as go
from controllers.data_classification import TextClassifier
import os
import pickle


def classification_view():
    tab1, tab2, tab3 = st.tabs(["Ph√¢n lo·∫°i","Bi·ªÉu ƒë·ªì so s√°nh", "H∆∞·ªõng d·∫´n "])
    with tab1:
        st.title("üìö Text Classification - Ph√¢n lo·∫°i vƒÉn b·∫£n")

        # Ch·ªçn dataset
        dataset_list = [
            "IMDb Review", "Yelp Review", "Amazon Review", 
            "TREC", "Yahoo! Answer", "AG's News", "Sogou News", "DBPedia"
        ]
        dataset_name = st.selectbox("üóÇ Ch·ªçn Dataset", dataset_list)

        # Ch·ªçn thu·∫≠t to√°n
        model_list = ["Naive Bayes", "Logistic Regression", "SVM", "K-Nearest Neighbors", "Decision Tree"]
        model_type = st.selectbox("ü§ñ Ch·ªçn Thu·∫≠t to√°n Ph√¢n Lo·∫°i", model_list)

        # N·∫øu ch·ªçn KNN, cho ph√©p ch·ªçn s·ªë l∆∞·ª£ng l·ªõp (ch·ªâ s·ªë l·∫ª)
        if model_type == "K-Nearest Neighbors":
            n_neighbors = st.slider("üî¢ Ch·ªçn s·ªë l∆∞·ª£ng l·ªõp (k - ch·ªâ s·ªë l·∫ª)", min_value=1, max_value=20, value=5, step=2)

        # N√∫t train model
        if st.button("üöÄ Train Model"):
            if model_type == "K-Nearest Neighbors":
                classifier = TextClassifier(dataset_name, model_type, n_neighbors)
            else:
                classifier = TextClassifier(dataset_name, model_type, None)

            # 1Ô∏è‚É£ Hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh
            progress_bar = st.progress(0)
        
            # 2Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi progress bar c·∫≠p nh·∫≠t theo th·ªùi gian th·ª±c
            accuracy, train_time = classifier.train_model(progress_bar)

            # 3Ô∏è‚É£ Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.success(f"‚úÖ M√¥ h√¨nh '{model_type}' ƒë·∫°t ƒë·ªô ch√≠nh x√°c: {accuracy * 100:.4f}%")
            st.write(f"‚è≥ Th·ªùi gian hu·∫•n luy·ªán: {train_time:.4f} gi√¢y")

            # 4Ô∏è‚É£ L∆∞u m√¥ h√¨nh v√†o session ƒë·ªÉ s·ª≠ d·ª•ng khi test
            if "comparison_data" not in st.session_state:
                st.session_state["comparison_data"] = {}

            if dataset_name not in st.session_state["comparison_data"]:
                st.session_state["comparison_data"][dataset_name] = {}

            st.session_state["comparison_data"][dataset_name][model_type] = {
                "accuracy": accuracy,
                "train_time": train_time
            }

        # D·ª± ƒëo√°n vƒÉn b·∫£n m·ªõi
        st.markdown("### üìù D·ª± ƒëo√°n VƒÉn B·∫£n M·ªõi")
        user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n lo·∫°i", "")

        if st.button("üéØ D·ª± ƒëo√°n"):
            try:
                if model_type == "K-Nearest Neighbors":
                    classifier = TextClassifier(dataset_name, model_type, n_neighbors)
                else:
                    classifier = TextClassifier(dataset_name, model_type, None)
                prediction = classifier.predict([user_input])  # C·∫ßn truy·ªÅn v√†o d·∫°ng list
                st.info(f"üìå **D·ª± ƒëo√°n:** {prediction[0]}")
            except ValueError as e:
                st.error(str(e))

    with tab2:
        st.title("üìä Bi·ªÉu ƒë·ªì So S√°nh")
        st.write("üîç So s√°nh ƒë·ªô ch√≠nh x√°c c·ªßa c√°c thu·∫≠t to√°n ph√¢n lo·∫°i tr√™n c√°c dataset kh√°c nhau.")

        # L·∫•y danh s√°ch dataset ƒë√£ l∆∞u t·ª´ c√°c file trong th∆∞ m·ª•c 'pre-trained'
        saved_datasets = set()

        for model_folder in os.listdir("pre-trained"):
            model_path = os.path.join("pre-trained", model_folder)
            if os.path.isdir(model_path):  # Ch·ªâ x√©t th∆∞ m·ª•c model
                for filename in os.listdir(model_path):
                    if filename.endswith(".pkl"):
                        dataset_name = "_".join(filename.split("_")[1:]).replace(".pkl", "")
                        saved_datasets.add(dataset_name)

        saved_datasets = list(saved_datasets)  # Chuy·ªÉn th√†nh danh s√°ch ƒë·ªÉ hi·ªÉn th·ªã

        # Giao di·ªán ch·ªçn dataset ƒë·ªÉ so s√°nh
        dataset_to_compare = st.selectbox("Ch·ªçn dataset ƒë·ªÉ so s√°nh:", saved_datasets) if saved_datasets else None

        # Debug danh s√°ch dataset l·∫•y ƒë∆∞·ª£c
        print("DEBUG - Danh s√°ch dataset l·∫•y ƒë∆∞·ª£c:", saved_datasets)

        # ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a model
        saved_models_path = "pre-trained"

        saved_models = []
        for model_folder in os.listdir(saved_models_path):
            model_path = os.path.join(saved_models_path, model_folder)
            if os.path.isdir(model_path):
                for filename in os.listdir(model_path):
                    if filename.endswith(".pkl"):
                        model_name = filename.split("_")[0]  # L·∫•y model type
                        dataset_name = "_".join(filename.split("_")[1:]).replace(".pkl", "")
                        if dataset_name == dataset_to_compare:
                            saved_models.append((model_name, dataset_name))

        if saved_models:
            # T·∫°o danh s√°ch thu·∫≠t to√°n & c√°c ch·ªâ s·ªë quan tr·ªçng ƒë·ªÉ so s√°nh
            models = []
            train_times = []
            accuracies = []
            precision = []
            recall = []
            f1_score = []
            
            for model_type, dataset_name in saved_models:
                model_file = os.path.join(saved_models_path, model_type, f"{model_type}_{dataset_name}.pkl")

                print("DEBUG - ƒê∆∞·ªùng d·∫´n model_file:", repr(model_file))  # Debug ƒë∆∞·ªùng d·∫´n

                with open(model_file, "rb") as f:
                    data = pickle.load(f)

                # Ki·ªÉm tra data c√≥ ƒë√∫ng 3 ph·∫ßn t·ª≠ kh√¥ng
                if isinstance(data, tuple) and len(data) == 3:
                    model, vectorizer, model_data_dict = data
                else:
                    print(f"‚ö†Ô∏è File {model_file} kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng, b·ªè qua!")
                    continue  # B·ªè qua file l·ªói

                print("DEBUG - model_data_dict:", repr(model_data_dict))  # Ki·ªÉm tra d·ªØ li·ªáu th·ª±c t·∫ø

                models.append(model_type)
                accuracies.append(model_data_dict["accuracy"])
                train_times.append(model_data_dict["train_time"])
                precision.append(model_data_dict["precision"])
                recall.append(model_data_dict["recall"])
                f1_score.append(model_data_dict["f1_score"])

            # V·∫Ω bi·ªÉu ƒë·ªì Accuracy & Train Time v·ªõi hai tr·ª•c y
            fig_acc_time = go.Figure()
            
            fig_acc_time.add_trace(go.Bar(
                x=models, y=accuracies, name="Accuracy", 
                text=[f"{a*100:.2f}%" for a in accuracies], textposition='auto',
                yaxis='y1'
            ))
            
            fig_acc_time.add_trace(go.Scatter(
                x=models, y=train_times, name="Train Time", 
                text=[f"{t:.2f}s" for t in train_times], textposition='top center',
                yaxis='y2', mode='lines+markers'
            ))
            
            fig_acc_time.update_layout(
                title=f"So s√°nh Accuracy & Train Time tr√™n '{dataset_to_compare}'",
                xaxis_title="Thu·∫≠t to√°n",
                yaxis=dict(title="Accuracy", side="left", showgrid=False),
                yaxis2=dict(title="Train Time (s)", overlaying='y', side='right', showgrid=False),
                template="plotly_white"
            )
            st.plotly_chart(fig_acc_time)

            # V·∫Ω Precision
            fig_precision = go.Figure([go.Bar(x=models, y=precision, text=[f"{p*100:.2f}%" for p in precision], textposition='auto')])
            fig_precision.update_layout(title="So s√°nh Precision", xaxis_title="Thu·∫≠t to√°n", yaxis_title="Precision", template="plotly_white")
            st.plotly_chart(fig_precision)

            # V·∫Ω Recall
            fig_recall = go.Figure([go.Bar(x=models, y=recall, text=[f"{r*100:.2f}%" for r in recall], textposition='auto')])
            fig_recall.update_layout(title="So s√°nh Recall", xaxis_title="Thu·∫≠t to√°n", yaxis_title="Recall", template="plotly_white")
            st.plotly_chart(fig_recall)

            # V·∫Ω F1-score
            fig_f1 = go.Figure([go.Bar(x=models, y=f1_score, text=[f"{f*100:.2f}%" for f in f1_score], textposition='auto')])
            fig_f1.update_layout(title="So s√°nh F1-score", xaxis_title="Thu·∫≠t to√°n", yaxis_title="F1-score", template="plotly_white")
            st.plotly_chart(fig_f1)

        else:
            st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model n√†o cho dataset '{dataset_to_compare}'!")


    with tab3:
        st.markdown(
            """
            ### üìå H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng 
            - **Ch·ªçn Dataset**: B·∫°n c√≥ th·ªÉ ch·ªçn dataset t·ª´ danh s√°ch ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.
            - **Ch·ªçn Thu·∫≠t to√°n**: Ch·ªçn thu·∫≠t to√°n ph√¢n lo·∫°i m√† b·∫°n mu·ªën s·ª≠ d·ª•ng.
            - **Train Model**: Nh·∫•n n√∫t ƒë·ªÉ b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh.    
                - **L∆∞u √Ω**: H·ªá th·ªëng m·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng **TF-IDF** ƒë·ªÉ vector h√≥a d·ªØ li·ªáu v·ªõi gi·ªõi h·∫°n **5000 t·ª´ v·ª±ng**. 
            Gi·∫£m th·ªùi gian hu·∫•n luy·ªán, ƒë·ªìng th·ªùi ƒë·ªô ch√≠nh x√°c c≈©ng gi·∫£m. 
            Tr√™n th·ª±c t·∫ø, c√≥ th·ªÉ b·ªè gi·ªõi h·∫°n t·ª´ v·ª±ng ho·∫∑c s·ª≠ d·ª•ng vector h√≥a kh√°c nh∆∞ Word2Vec, GloVe, BERT, ... 
            Nh∆∞ng c≈©ng c·∫ßn m√°y t√≠nh c√≥ c·∫•u h√¨nh m·∫°nh v√† th·ªùi gian hu·∫•n luy·ªán c≈©ng l√¢u h∆°n.
            - **D·ª± ƒëo√°n VƒÉn b·∫£n M·ªõi**: Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n lo·∫°i v√† nh·∫•n n√∫t "D·ª± ƒëo√°n".  
                - **L∆∞u √Ω**: K·∫øt qu·∫£ hi·ªÉn th·ªã ch·ªâ s·ªë t∆∞∆°ng ·ª©ng v·ªõi nh√£n c·ªßa dataset nh∆∞ sau:
                    - **IDMB Review**: D√πng ƒë·ªÉ ph√¢n t√≠ch t√¨nh c·∫£m c·ªßa ng∆∞·ªùi d√πng ƒë·ªëi v·ªõi phim. **(0: Ti√™u c·ª±c, 1: T√≠ch c·ª±c.)** 
                    - **Yelp Review**: D√πng ƒë·ªÉ ph√¢n t√≠ch t√¨nh c·∫£m c·ªßa ng∆∞·ªùi d√πng ƒë·ªëi v·ªõi nh√† h√†ng. **(0: Ti√™u c·ª±c, 1: T√≠ch c·ª±c.)**  
                    - **Amazon Review**: D√πng ƒë·ªÉ ph√¢n t√≠ch t√¨nh c·∫£m c·ªßa ng∆∞·ªùi d√πng ƒë·ªëi v·ªõi s·∫£n ph·∫©m. **(0: Ti√™u c·ª±c, 1: T√≠ch c·ª±c.)**
                    - **TREC**: D√πng ƒë·ªÉ ph√¢n lo·∫°i c√¢u h·ªèi. 6 l·ªõp: DESC, ENTY, ABBR, HUM, LOC, NUM. **(0 - 5.)** 
                    - **Yahoo! Answer**: D√πng ƒë·ªÉ ph√¢n lo·∫°i c√¢u h·ªèi. 10 l·ªõp: DESC, ENTY, ABBR, HUM, LOC, NUM, DESC, ENTY, ABBR, HUM. **(0 - 9.)** 
                    - **AG's News**: D√πng ƒë·ªÉ ph√¢n lo·∫°i tin t·ª©c. 4 l·ªõp: World, Sports, Business, Sci/Tech. **(0 - 3.)**
                    - **Sogou News**: D√πng ƒë·ªÉ ph√¢n lo·∫°i tin t·ª©c. 5 l·ªõp: Sports, Finance, Entertainment, Automobile, Technology. **(0 - 4.)**
                    - **DBPedia**: D√πng ƒë·ªÉ ph√¢n lo·∫°i Wikipedia. 14 l·ªõp: Company, Educational Institution, Artist, Athlete, Office Holder, Mean of Transportation, Building, Natural Place, Village, Animal, Plant, Album, Film, Written Work. **(0 - 13.)**
            ---
            """
        )
        st.video("https://youtu.be/A4ZkI5JYRDA")
        st.caption("üé• H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Ph√¢n lo·∫°i vƒÉn b·∫£n")