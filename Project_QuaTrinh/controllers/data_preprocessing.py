import spacy
import nltk
import contractions
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.stem import PorterStemmer, SnowballStemmer
from spellchecker import SpellChecker
from spacy import displacy

# Táº£i mÃ´ hÃ¬nh ngÃ´n ngá»¯ English
nltk.download('punkt')

class TextPreprocessor:
    def __init__(self, text):
        """Khá»Ÿi táº¡o lá»›p vá»›i vÄƒn báº£n Ä‘áº§u vÃ o"""
        self.text = text
        self.nlp = spacy.load("en_core_web_sm")  # MÃ´ hÃ¬nh NLP cá»§a SpaCy
        self.spell = SpellChecker()  # Bá»™ kiá»ƒm tra lá»—i chÃ­nh táº£
        self.doc = self.nlp(self.text)  # PhÃ¢n tÃ­ch vÄƒn báº£n vá»›i SpaCy
        self.stemmer = PorterStemmer()
        self.snowball = SnowballStemmer(language="english")

    def sentence_tokenization(self):
        """TÃ¡ch cÃ¢u"""
        return [sent.text for sent in self.doc.sents]

    def word_tokenization(self):
        """TÃ¡ch tá»«"""
        return [token.text for token in self.doc]

    def remove_stopwords_punctuation(self):
        """XÃ³a stop words vÃ  dáº¥u cÃ¢u"""
        return [token.text for token in self.doc if not token.is_stop and not token.is_punct]

    def to_lowercase(self):
        """Viáº¿t thÆ°á»ng táº¥t cáº£ tá»«"""
        return self.text.lower()

    def stemming(self, method="snowball"):
        """Ãp dá»¥ng stemming (Porter hoáº·c Snowball)"""
        stem_func = self.snowball.stem
        return [stem_func(token.text) for token in self.doc]

    def lemmatization(self):
        """ÄÆ°a tá»« vá» dáº¡ng gá»‘c"""
        return [(token.text, token.lemma_) for token in self.doc]

    def pos_tagging(self):
        """XÃ¡c Ä‘á»‹nh tá»« loáº¡i (POS tagging)"""
        return [(token.text, token.pos_) for token in self.doc]

    def expand_contractions(self):
        """Sá»­a láº¡i cÃ¡c tá»« viáº¿t táº¯t"""
        return contractions.fix(self.text)

    def correct_spelling(self):
        """Sá»­a lá»—i chÃ­nh táº£"""
        words = self.text.split()
        return " ".join([self.spell.correction(word) if self.spell.correction(word) else word for word in words])

    def named_entity_recognition(self):
        """Nháº­n diá»‡n thá»±c thá»ƒ (NER)"""
        return [(entity.text, entity.label_) for entity in self.doc.ents]

    def visualize_entities(self):
        """Hiá»ƒn thá»‹ NER báº±ng HTML Ä‘á»ƒ Streamlit hiá»ƒn thá»‹"""
        html = displacy.render(self.doc, style="ent", page=True)
        return html  # Tráº£ vá» HTML Ä‘á»ƒ hiá»ƒn thá»‹ trong Streamlit
    
    def summary(self):
        """TÃ³m táº¯t táº¥t cáº£ cÃ¡c bÆ°á»›c xá»­ lÃ½"""
        print("ğŸ“Œ **Sentence Tokenization:**", self.sentence_tokenization(), "\n")
        print("ğŸ“Œ **Word Tokenization:**", self.word_tokenization(), "\n")
        print("ğŸ“Œ **Remove Stopwords & Punctuation:**", self.remove_stopwords_punctuation(), "\n")
        print("ğŸ“Œ **Lowercase Text:**", self.to_lowercase(), "\n")
        print("ğŸ“Œ **Stemming (Porter):**", self.stemming("porter"), "\n")
        print("ğŸ“Œ **Lemmatization:**", self.lemmatization(), "\n")
        print("ğŸ“Œ **POS Tagging:**", self.pos_tagging(), "\n")
        print("ğŸ“Œ **Expand Contractions:**", self.expand_contractions(), "\n")
        print("ğŸ“Œ **Correct Spelling:**", self.correct_spelling(), "\n")
        print("ğŸ“Œ **Named Entities:**", self.named_entity_recognition(), "\n")
